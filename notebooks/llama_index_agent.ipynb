{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, List, Mapping, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.llms import (\n",
    "    CustomLLM,\n",
    "    CompletionResponse,\n",
    "    CompletionResponseGen,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.core.llms.callbacks import llm_completion_callback\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stas_chi/Library/Caches/pypoetry/virtualenvs/izba_ai-UUHFOrDR-py3.11/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in OurLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class OurLLM(CustomLLM):\n",
    "    context_window: int = 128e3\n",
    "    num_output: int = 8192\n",
    "    model_name: str = \"nebius\"\n",
    "    dummy_response: str = \"Dummy response\"\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            context_window=self.context_window,\n",
    "            num_output=self.num_output,\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        client = OpenAI(\n",
    "            base_url=\"https://api.studio.nebius.ai/v1/\",\n",
    "            api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n",
    "            messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=8192,\n",
    "            top_p=0.9\n",
    "        )\n",
    "\n",
    "        return CompletionResponse(\n",
    "            text=completion.choices[0].message.content\n",
    "        )\n",
    "    \n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> CompletionResponseGen:\n",
    "        response = \"\"\n",
    "        for token in self.dummy_response:\n",
    "            response += token\n",
    "            yield CompletionResponse(text=response, delta=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "def divide(a: float, b: float) -> float:\n",
    "    return a/b\n",
    "\n",
    "divide_tool = FunctionTool.from_defaults(fn=divide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://api.tavily.com/search\"\n",
    "\n",
    "# Define the parameters for the API request\n",
    "payload = {\n",
    "    \"api_key\": os.environ.get(\"TAVILY_API_KEY\"),\n",
    "    \"query\": \"What is the latest share price of LSEG?\",\n",
    "    \"search_depth\": \"basic\",\n",
    "    \"include_answer\": True,\n",
    "    \"include_images\": False,\n",
    "    \"include_image_descriptions\": False,\n",
    "    \"include_raw_content\": False,\n",
    "    \"max_results\": 5,\n",
    "    \"include_domains\": [],\n",
    "    \"exclude_domains\": []\n",
    "}\n",
    "\n",
    "# Set the appropriate headers (if needed, such as for content type)\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(URL,headers=headers,data=json.dumps(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The latest share price of London Stock Exchange Group plc (LSEG) is currently trading at a record high, having surged by over 12% this year, outperforming the FTSE 100 and FTSE 250 indices.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OurLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools([multiply_tool, add_tool, divide_tool], llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stas_chi/Library/Caches/pypoetry/virtualenvs/izba_ai-UUHFOrDR-py3.11/lib/python3.11/site-packages/llama_index/core/schema.py:79: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `int` but got `float` with value `128000.0` - serialized value may not be as expected\n",
      "  data = handler(self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 1243b793-cda7-4658-8595-d35bcd00fb91. Step input: Solve the following equation: 10 = 5x\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: divide\n",
      "Action Input: {'a': 10, 'b': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 2.0\n",
      "\u001b[0m> Running step 78ebb35c-e880-4cda-a76a-45bb7b06c79b. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The value of x is 2.0.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Solve the following equation: 10 = 5x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "izba_ai-UUHFOrDR-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
