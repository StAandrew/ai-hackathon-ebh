import json
import os
import pandas as pd
import sqlite3

from dotenv import load_dotenv
from jinja2 import Environment, FileSystemLoader, Template
from openai import OpenAI

load_dotenv("/Users/stas_chi/Documents/Projects/Izba AI/izba-ai/backend/.env")

llm_client = OpenAI(
    base_url="https://api.studio.nebius.ai/v1/",
    api_key=os.environ.get("NEBIUS_API_KEY"),
)

file_loader = FileSystemLoader("/Users/stas_chi/Documents/Projects/Izba AI/izba-ai/backend/prompts")  # Specify the directory containing your template file
env = Environment(loader=file_loader)

columns = [
    'id',
    'url',
    'number_of_bedrooms',
    'number_of_bathrooms',
    'title',
    'description',
    'property_type',
    'address',
    'postcode_short',
    'postcode_long',
    'price',
    'added_on',
    'agent_name',
    'agent_phone_number',
    'image1_url',
    'image2_url',
    'image3_url',
    'image4_url'
]

def get_current_market_data(user_query: str) -> dict[str,str]:
    """Tool that has access to all current properties for sale listings data in Kensington and Chelsea. 

    This tool always provides all info that you need about current listings.

    Takes in a user query as an input and returns the output in the following format:
    {
        "debug_info": any debugging info available,
        "llm_response": final response generated by the LLM
    }
    """
    template = env.get_template('current_market_data_to_sql.jinja2')
    # Render the template
    prompt = template.render(
        user_query = user_query
    )

    completion = llm_client.chat.completions.create(
        model="meta-llama/Meta-Llama-3.1-405B-Instruct",
        messages=[
        {
            "role": "system",
            "content": prompt
        }
        ],
        temperature=0,
        max_tokens=1000,
        top_p=0.9
    )

    try:
        SQL_QUERY = json.loads(completion.choices[0].message.content)["SQL_QUERY"]
    except:
        print("Failed to load JSON from LLM output")

    # Step 1: Connect to the SQLite database (or create it if it doesn't exist)
    conn = sqlite3.connect('/Users/stas_chi/Documents/Projects/Izba AI/izba-ai/backend/databases/scraped_listings.db')  # Replace with your database file

    # Step 2: Create a cursor object
    cursor = conn.cursor()

    # Step 3: Run a SELECT query to fetch data
    cursor.execute(SQL_QUERY)

    # Step 4: Process and print the results
    rows = cursor.fetchall()

    # Print the results
    df = pd.DataFrame(
        data = rows,
        columns = columns
    )
    # Step 5: Close the connection
    conn.close()

    return_data = []
    for row in rows:
        return_data.append(
            {
                "title": row[4],
                "price": row[10],
                "address": row[7],
                "postcode": row[9],
                "number_of_bedrooms": row[2],
                "number_of_bathrooms": row[3],
                "image1_url": row[14]
            }
        )


    return {
        "debug_info": SQL_QUERY,
        "return_data": return_data
    }